📌 IT 기업 기술 블로그 분석
— 문제 정의 방식 관점에서 바라보기
✍️ 분석 목적
이 팀은 문제를 어떻게 정의했고,
왜 이 해결책을 선택했는가?

기술 자체를 배우기보다는,
문제를 인식하고 정의하는 사고 과정을 이해하는 것을 목표로 한다.
🔍 분석 대상
기업 / 팀: 카카오페이 기술 블로그
글 제목: 일 41TB, 200억 건의 로그를 ClickStack으로 실시간 처리하기 - 호그와트 도서관 프로젝트
작성 연도: 2026년 2월 23일
다루는 주제: 대규모 로그 수집 및 처리
① 문제는 어디서 시작됐는가?
이 글에서 문제는 어떤 계기로 등장했는가?
서비스의 빠른 성장세로 일일 로그량 급증
저장 비용과 검색 성능 사이의 트레이드 오프
이상 징후 탐지, 실시간 지표 모니터링 등 즉각적인 데이터 처리에 대한 비즈니스 요구 강해짐
👉 **문제의 ‘출발점’**은 무엇이었는지 정리한다.
② 왜 이게 ‘문제’라고 판단했는가?
단순한 불편이 아니라,
왜 반드시 해결해야 할 문제라고 판단했는가?
비용 문제
로그량의 급격한 증가에 따라 OpenSearch 비용 8배 이상 증가
성능 문제
로그량이 너무 많아 검색 속도가 느려짐
필요한 데이터를 실시간 시각화하는 데 지연 발생
확장성 문제
특정 솔루션에 종속되어 대량의 트래픽 유입 시 유연한 확장이 어려움
👉 ‘문제’와 ‘현상’을 구분하는 기준에 집중한다.
③ 문제를 어떻게 쪼갰는가?
하나의 큰 문제를
어떤 기준으로 분해했는가?
저장 문제 (Volume / Cost)
일 41TB, 200억 건의 로그 데이터
기존 OpenSearch 구조에서 비용이 기하급수적으로 증가
조회 문제 (Latency / Query)
대용량 로그로 인해 검색 속도 저하
장애 분석 및 운영 대응에 필요한 즉각적인 조회가 어려움
실시간 처리 문제 (Freshness / Streaming)
이상 징후 탐지, 실시간 지표 시각화 요구
배치 기반 로그 처리로는 비즈니스 요구를 충족하지 못
👉 문제를 관리 가능한 단위로 나누는 방식을 본다.
④ 대안은 무엇이 있었는가?
현재 선택한 해결책 외에
고려했던 다른 선택지는 무엇이었는가?
전략: 대용량 로그 처리에 최적화된 파이프라인을 재설계하는 전략
해결책:
OTLP Proto 인코딩 도입
기존 Filebeat는 로그 한 줄을 JSON 형태로 Kafka 메시지 한 개씩 전송
OTLP Proto 인코딩으르 통해 필드명 대신 숫자 태그 사용
여러 로그를 하나의 메시지로 묶어 전송
OpenTelemetry Collector & ClickHouse를 통해 Topic 처리
초기에는 로그 타입별 Logstash 구조를 사용
특정 로그 타입의 폭증이 전체 파이프라인 지연으로 이어지는 문제가 발생
서비스 단위로 Topic을 분리하고 Fluentd를 도입
성능 테스트를 통해 대규모 트래픽 환경에서도 안정적인 처리 성능을 확보했음을 확인
피크 타임에 리소스를 재분배해 중요 로그를 우선 처리할 수 있는 구조를 마련
HyperDX: 개발 크루용 로그 조회 UI
대안 1. OpenSearch
낮은 압축률
대용량 집계 비효율
컬럼 검색 취약
비용 증가
대안 2. Grafana Loki
라벨 기반 제약
집계 기능 부족
카디널리티 한계
쿼리 언어 한계
최종 전략. Click House
대용량 집계
컬럼 검색
비용 효율
유연한 스키마
👉 “왜 이 방법만 있었는가?”가 아니라
**“왜 다른 방법은 선택되지 않았는가?”**에 집중한다.
⑤ 왜 이 해결책을 선택했는가?
최종 선택의 판단 기준은 무엇이었는가?
이 팀에서 가장 우선시된 기준
로그 규모가 계속 증가하는 상황에서도 성능과 비용이 함께 예측 가능하게 유지되는 구조를 만드는 것
선택한 해결책
파이프라인 구조 자체를 다시 설계
이 과정에서 ClickHouse와 OpenTelemetry Collector가 구조적 문제를 해결하는 데 적합한 역할을 수행할 수 있었기 때문에 채택
ClickHouse는 대규모 집계와 분석에 강점을 보였고, 높은 압축률을 통해 로그 증가에 따른 비용 문제 완화
OpenTelemetry Collector는 다양한 로그 소스를 단일 수집 계층으로 통합
로그의 장기 보관은 S3로 분리하여 지연 및 부하 최소화
‘호그와트 도서관’이라는 콘셉트의 UI
내부 사용자들이 로그에 쉽게 접근하고 활용할 수 있도록 설계
HyperDX는 컬럼 기반 필터로 검색이 빠르고 시간 순으로 로그 흐름 파악하기 용이
세션 추적과 대시보드, 알람 기능 탑
👉 기술 그 자체보다
선택의 기준과 우선순위를 파악한다.
⑥ 결과를 어떻게 검증했는가?
해결책 적용 후,
문제가 실제로 해결되었음을 어떻게 확인했는가?
이 글에서 성능과 비용 개선 결과를 정량 지표로 제시하고 있다.
성능 관점
로그 지연: 수분 ~ 수 시간에서 20초 이내로 단축
초당 처리량: 기존에는 측정 데이터가 없으나 현재 초당 83만 건이 처리
OpenTelemetry 처리는 단일 Topic consume으로 6배 향상
장애 대응: 기존에는 과거 로그에 변화가 없었으나 Scale Out으로 과거 로그까지 처리됨
비용 효율 관점
전체 비용: IDC 물리 서버 기준 85.6% 절감
처리기: 메모리 사용량 96% 감소
저장소: 컬럼형 저장 및 ZSTD 압축을 통해 78% 절감
저장 용량: Parquet 및 ZSTD 압축을 통해 최대 90%까지 절감
운영 복잡도: 기존 kafka Topic 300개 -> 18개로 줄이고 Fluentd 1,000여 개 -> OpenTelemetry 150여 개로 줄임
👉 *“잘 된 것 같다”*가 아니라
어떻게 ‘증명’했는지를 본다.
🧠 분석을 통해 얻은 인사이트
이 글을 통해 배운 문제 정의 방식은 무엇인가?
대규모 시스템에서는 '가장 유명한 기술'이 반드시 '정답'은 아니라는 점을 배웠습니다. 카카오페이 팀은 ELK라는 표준적인 선택지에서 벗어나, 자신들의 데이터 패턴(대량의 쓰기, 집계 위주의 읽기)을 정확히 분석하여 ClickHouse라는 최적의 도구를 찾아냈습니다. 특히 기술적 해결에만 머물지 않고 이를 '플랫폼(Pallas-v2/ClickStack)'화하여 내부 고객(개발자)의 경험을 개선한 점이 인상적입니다.
🔁 내 관점에서의 정리
이 방식을 내 분석/업무에 적용한다면?

이번 분석은 개별 기술의 동작이나 성능보다, 대규모 로그를 운영하는 조직이 어떤 기준으로 구조를 선택하는지를 이해하는 데 초점이 맞춰져 있어 상대적으로 정리하기 어려웠다. 그러나 글을 따라가며 느낀 점은, 이 프로젝트의 핵심은 특정 기술을 도입했다는 사실보다 기존 구조가 더 이상 운영 요구를 감당하지 못한다는 문제를 명확히 인식하고, 이를 해결하기 위해 파이프라인 전체를 다시 설계했다는 데 있었다. 특히 성능이나 비용 개선 수치는 결과라기보다, 이러한 구조적 전환이 필요했음을 뒷받침하는 근거로 제시되었고, 기술 선택은 그 문제 정의에 자연스럽게 따라온 결과로 보였다.
✅ 마무리 한 줄 요약
이 글에서 가장 인상 깊었던 문제 정의 포인트 한 가지

가장 인상 깊었던 문제 정의 포인트는 로그 처리 성능이나 비용 문제를 개별 기술의 한계로 보지 않고, 기존 파이프라인 구조 자체가 현재의 로그 규모와 운영 요구에 맞지 않게 된 상태로 인식한 점이다. 이는 단순한 성능 개선이나 비용 절감이 아니라, 구조적 전환이 필요하다는 판단으로 문제의 범위를 확장한 지점이었다.

